{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMza/1cfr+Z2rFz/XML+IHP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wpowell31/Disease-prediction-python/blob/main/LungCancerTransferLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wn8ST5ji5B0S"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "import cv2\n",
        "import gc\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "from zipfile import ZipFile\n",
        "\n",
        "data_path = 'lung-and-colon-cancer-histopa\\\n",
        "thological-images.zip'\n",
        "\n",
        "with ZipFile(data_path,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The data set has been extracted.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/lung_colon_image_set/lung_image_sets'\n",
        "classes = os.listdir(path)\n",
        "classes"
      ],
      "metadata": {
        "id": "V0lNBL155KXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "path = '/lung_colon_image_set/lung_image_sets'\n",
        "\n",
        "for cat in classes:\n",
        "    image_dir = f'{path}/{cat}'\n",
        "    images = os.listdir(image_dir)\n",
        "\n",
        "    fig, ax = plt.subplots(1, 3, figsize = (15, 5))\n",
        "    fig.suptitle(f'Images for {cat} category . . . .',\n",
        "                 fontsize = 20)\n",
        "\n",
        "    for i in range(3):\n",
        "        k = np.random.randint(0, len(images))\n",
        "        img = np.array(Image.open(f'{path}/{cat}/{images[k]}'))\n",
        "        ax[i].imshow(img)\n",
        "        ax[i].axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2Exv2tTt5K80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 256\n",
        "SPLIT = 0.2\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for i, cat in enumerate(classes):\n",
        "  images = glob(f'{path}/{cat}/*.jpeg')\n",
        "\n",
        "  for image in images:\n",
        "    img = cv2.imread(image)\n",
        "\n",
        "    X.append(cv2.resize(img, (IMG_SIZE, IMG_SIZE)))\n",
        "    Y.append(i)\n",
        "\n",
        "X = np.asarray(X)\n",
        "one_hot_encoded_Y = pd.get_dummies(Y).values\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(\n",
        "  X, one_hot_encoded_Y, test_size = SPLIT, random_state = 2022)\n",
        "print(X_train.shape, X_val.shape)"
      ],
      "metadata": {
        "id": "K_7euGo85LEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "pre_trained_model = InceptionV3(\n",
        "    input_shape = (IMG_SIZE, IMG_SIZE, 3),\n",
        "    weights = 'imagenet',\n",
        "    include_top = False\n",
        ")"
      ],
      "metadata": {
        "id": "m8cxcAmS5xJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "\n",
        "x = layers.Flatten()(last_output)\n",
        "\n",
        "x = layers.Dense(256,activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "x = layers.Dense(128,activation='relu')(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "\n",
        "output = layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(pre_trained_model.input, output)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "IVB-LWsC5xRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs = {}):\n",
        "    if logs.get('val_accuracy') > 0.90:\n",
        "      print('\\n Validation accuracy has reached upto 90%\\\n",
        "      so, stopping further training.')\n",
        "      self.model.stop_training = True\n",
        "\n",
        "es = EarlyStopping(patience = 3,\n",
        "                   monitor = 'val_accuracy',\n",
        "                   restore_best_weights = True)\n",
        "\n",
        "lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
        "                       patience = 2,\n",
        "                       factor = 0.5,\n",
        "                       verbose = 1)\n",
        "\n",
        "\n",
        "history = model.fit(X_train, Y_train,\n",
        "                    validation_data = (X_val, Y_val),\n",
        "                    batch_size = BATCH_SIZE,\n",
        "                    epochs = EPOCHS,\n",
        "                    verbose = 1,\n",
        "                    callbacks = [es, lr, myCallback()])"
      ],
      "metadata": {
        "id": "rnxHAuTB5xYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df.loc[:,['loss','val_loss']].plot()\n",
        "history_df.loc[:,['accuracy','val_accuracy']].plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yPgXJm9q5xfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Y_pred = model.predict(X_val)\n",
        "\n",
        "Y_val = np.argmax(Y_val, axis=1)\n",
        "Y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "metrics.confusion_matrix(Y_val, Y_pred)"
      ],
      "metadata": {
        "id": "awfVzvK25xlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(Y_val, Y_pred,\n",
        "                                    target_names=classes))"
      ],
      "metadata": {
        "id": "Dfy9XJbp5LL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QBi9kRb06ai5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}