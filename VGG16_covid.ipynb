{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWKkwjqiLWq/zfGG8hl8XH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wpowell31/Disease-prediction-python/blob/main/VGG16_covid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izZaN4GXEr19",
        "outputId": "b8547000-dd40-4502-e361-4bacc50f5e25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/COVID Chest X-Ray Analysis\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 403, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /content/gdrive/MyDrive/COVID Chest X-Ray Analysis. Or use the environment method.\n",
            "unzip:  cannot find or open *.zip, *.zip.zip or *.zip.ZIP.\n",
            "\n",
            "No zipfiles found.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import keras\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import  Flatten, Dense, Dropout\n",
        "from keras.applications import VGG16\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D, GlobalAveragePooling2D\n",
        "import keras_preprocessing\n",
        "from keras_preprocessing import image\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras import callbacks\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "%cd /content/gdrive/\"My Drive\"/\"COVID Chest X-Ray Analysis\"\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/COVID Chest X-Ray Analysis\"\n",
        "!kaggle datasets download -d plameneduardo/sarscov2-ctscan-dataset\n",
        "!unzip \\*.zip  && rm *.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "disease_types=['COVID', 'non-COVID']\n",
        "data_dir = '/content/gdrive/MyDrive/COVID Chest X-Ray Analysis/'\n",
        "train_dir = os.path.join(data_dir)\n",
        "\n",
        "\n",
        "train_data = []\n",
        "for defects_id, sp in enumerate(disease_types):\n",
        "    for file in os.listdir(os.path.join(train_dir, sp)):\n",
        "        train_data.append(['{}/{}'.format(sp, file), defects_id, sp])\n",
        "train = pd.DataFrame(train_data, columns=['File', 'DiseaseID','Disease Type'])\n",
        "\n",
        "\n",
        "IMAGE_SIZE = 150\n",
        "def read_image(filepath):\n",
        "    return cv2.imread(os.path.join(data_dir, filepath))\n",
        "def resize_image(image, image_size):\n",
        "    return cv2.resize(image.copy(), image_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "\n",
        "X_train = np.zeros((train.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "for i, file in tqdm(enumerate(train['File'].values)):\n",
        "    image = read_image(file)\n",
        "    if image is not None:\n",
        "        X_train[i] = resize_image(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "X_Train = X_train / 255.\n",
        "print(X_Train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRH9aBJxE0GN",
        "outputId": "87f1573e-8230-4e87-8d5a-0703ceda99bd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2481it [07:34,  5.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2481, 150, 150, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train = train['DiseaseID'].values\n",
        "Y_train = to_categorical(Y_train, num_classes=2)\n",
        "\n",
        "\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_Train, Y_train, test_size=0.1)"
      ],
      "metadata": {
        "id": "s4pKMpUsFBDV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "vgg16_model = VGG16(weights = 'imagenet', include_top = False,input_shape=(150,150,3))\n",
        "x = vgg16_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "predictions = Dense(2, activation = 'softmax')(x)\n",
        "model = Model(vgg16_model.input,predictions)\n",
        "for layer in vgg16_model.layers:\n",
        "    layer.trainable = False\n",
        "optimizer = Adam(lr=0.0002)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model._name = \"VGG16_Architecture\"\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6SgPy57FCME",
        "outputId": "1ba76c41-9b7f-4740-f2d4-8648476d1fd2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"VGG16_Architecture\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 512)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 512)              2048      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,849,602\n",
            "Trainable params: 133,378\n",
            "Non-trainable params: 14,716,224\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_datagen = ImageDataGenerator(rotation_range=40,\n",
        "                        width_shift_range=0.2,\n",
        "                        height_shift_range=0.2,\n",
        "                        zoom_range=0.2,\n",
        "                        horizontal_flip=True,\n",
        "                        vertical_flip=True,\n",
        "                        shear_range=0.2)\n",
        "\n",
        "train_generator = training_datagen.flow(\n",
        "\tX_train, Y_train,\n",
        "batch_size=64\n",
        ")\n",
        "training_datagen.fit(X_train)\n",
        "\n",
        "\n",
        "filepath=\"VGG16_Model.hdf5\"\n",
        "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss',save_best_only=True, mode='min',verbose=1)\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = model.fit_generator(train_generator, steps_per_epoch=16, epochs=20,\n",
        "                              validation_data=(X_val, Y_val),validation_steps=50,callbacks=callbacks_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHPQ-CEQFCWm",
        "outputId": "5de88407-9f12-4bc2-d6f4-376815536b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-ee889c2b1f01>:20: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(train_generator, steps_per_epoch=16, epochs=20,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            " 5/16 [========>.....................] - ETA: 2:57 - loss: 0.9402 - accuracy: 0.5688"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('TraiN & Val Acc VS Epochs')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iIyLxF_EHOv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epochs = range(len(acc))\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('TraiN & Val Loss VS Epochs')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OSSUl7v0FDB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"VGG16_Model.hdf5\")\n",
        "score = model.evaluate(X_val, Y_val ,verbose=1)\n",
        "print('Test Loss:', score[0])\n",
        "print('Test accuracy:', score[1]*100)\n",
        "\n",
        "8/8 [==============================] - 38s 437ms/step - loss: 0.3655 - accuracy: 0.8612\n",
        "Test Loss: 0.3781876862049103\n",
        "Test accuracy: 85.14056205749512\n",
        "\n",
        "Y_pred = model.predict(X_val)\n",
        "Y_predx = np.argmax(Y_pred, axis = -1)\n",
        "Y_valx = np.argmax(Y_val, axis = -1)\n",
        "cf_matrix = confusion_matrix(Y_valx, Y_predx)\n",
        "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
        "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
        "                cf_matrix.flatten()]\n",
        "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
        "                     cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
        "          zip(group_names,group_counts,group_percentages)]\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "sns.heatmap(cf_matrix, annot = labels, fmt = '')\n",
        "plt.title(\"Confusion Matrix\")"
      ],
      "metadata": {
        "id": "bM0EMWKpFDbZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}